{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36025c09-2da3-4839-8cef-f572d187b7b4",
   "metadata": {},
   "source": [
    "# 1. Brain Source Localization with ConvDip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7420bf1a-efa8-4c24-8ad4-e8ca759fabb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "357c69a8-2553-4cf8-9f91-a63437d4aeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing task: LA\n",
      "(59, 3)\n",
      "result saved in: ./result//sample/Test_result_evoked_LA.mat\n",
      "processing task: LV\n",
      "(59, 3)\n",
      "result saved in: ./result//sample/Test_result_evoked_LV.mat\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The subject underwent four tasks, and corresponding EEG data were collected.\n",
    "task list: ['LA','LV','RA','RV']\n",
    "\"\"\"\n",
    "# you can choose single or multiple task ids from task list ['LA','LV','RA','RV']\n",
    "tasks = ['LA', 'LV'] # or 'LA' or ['LA'], etc.\n",
    "# set your result path\n",
    "result_path = './result/'\n",
    "ConvDip_ESI(tasks, result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "417f0ce4-63f6-43d7-a5e0-45b0fcde8611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load result for task: LA\n",
      "(1984, 241)\n"
     ]
    }
   ],
   "source": [
    "# choose only ONE task from ['LA','LV','RA','RV']\n",
    "task = 'LA' \n",
    "s_pred = load_result(task, result_path)\n",
    "print(s_pred.shape) # s_pred: estimated sources at different timepoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6838b1-be32-4b25-b9fc-b67bb05ad767",
   "metadata": {},
   "source": [
    "# 2. 3D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10453c03-395e-4c1f-a004-e1cbd19f9001",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run brain.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "695efb0b-c329-4e8c-8af9-0e06cd227f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\Users\\dimpa\\mne_data\\MNE-sample-data\\MEG\\sample\\sample_audvis_filt-0-40_raw.fif...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Read a total of 4 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "        Average EEG reference (1 x 60)  idle\n",
      "    Range : 6450 ... 48149 =     42.956 ...   320.665 secs\n",
      "Ready.\n",
      "319 events found on stim channel STI 014\n",
      "Event IDs: [ 1  2  3  4  5 32]\n",
      "Removing projector <Projection | Average EEG reference, active : False, n_channels : 60>\n",
      "Not setting metadata\n",
      "72 matching events found\n",
      "Setting baseline interval to [-0.19979521315838786, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 3)\n",
      "Loading data for 72 events and 106 original time points ...\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on MAG : ['MEG 1711']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "    Rejecting  epoch based on EOG : ['EOG 061']\n",
      "17 bad epochs dropped\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 4.1e-09 (2.2e-16 eps * 305 dim * 6.1e+04  max singular value)\n",
      "    Estimated rank (mag + grad): 302\n",
      "    MEG: rank 302 computed from 305 data channels with 3 projectors\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "    Setting small MEG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 305 -> 302\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Number of samples used : 2035\n",
      "[done]\n",
      "Computing rank from data with rank=None\n",
      "    Using tolerance 2.8e-09 (2.2e-16 eps * 305 dim * 4.2e+04  max singular value)\n",
      "    Estimated rank (mag + grad): 302\n",
      "    MEG: rank 302 computed from 305 data channels with 3 projectors\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "    Setting small MEG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 305 -> 302\n",
      "Estimating covariance using EMPIRICAL\n",
      "Done.\n",
      "Number of samples used : 1705\n",
      "[done]\n",
      "Reading forward solution from c:\\Project\\SSW_555\\Epilapcy Model\\data\\meg-fwd.fif...\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    [done]\n",
      "    Reading a source space...\n",
      "    Computing patch statistics...\n",
      "    Patch information added...\n",
      "    [done]\n",
      "    2 source spaces read\n",
      "    Desired named matrix (kind = 3523) not available\n",
      "    Read MEG forward solution (1984 sources, 102 channels, free orientations)\n",
      "    Source spaces transformed to the forward solution coordinate frame\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 4e-14 (2.2e-16 eps * 102 dim * 1.8  max singular value)\n",
      "    Estimated rank (mag): 99\n",
      "    MAG: rank 99 computed from 102 data channels with 3 projectors\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 2.3e-14 (2.2e-16 eps * 102 dim * 1  max singular value)\n",
      "    Estimated rank (mag): 99\n",
      "    MAG: rank 99 computed from 102 data channels with 3 projectors\n",
      "Making LCMV beamformer with rank {'mag': 99}\n",
      "Computing inverse operator with 102 channels.\n",
      "    102 out of 102 channels remain after picking\n",
      "Selected 102 channels\n",
      "Whitening the forward solution.\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "Computing rank from covariance with rank={'mag': 99}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing beamformer filters for 1984 sources\n",
      "Filter computation complete\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 4e-14 (2.2e-16 eps * 102 dim * 1.8  max singular value)\n",
      "    Estimated rank (mag): 99\n",
      "    MAG: rank 99 computed from 102 data channels with 3 projectors\n",
      "Computing rank from covariance with rank=None\n",
      "    Using tolerance 2.3e-14 (2.2e-16 eps * 102 dim * 1  max singular value)\n",
      "    Estimated rank (mag): 99\n",
      "    MAG: rank 99 computed from 102 data channels with 3 projectors\n",
      "Making LCMV beamformer with rank {'mag': 99}\n",
      "Computing inverse operator with 102 channels.\n",
      "    102 out of 102 channels remain after picking\n",
      "Selected 102 channels\n",
      "Whitening the forward solution.\n",
      "    Created an SSP operator (subspace dimension = 3)\n",
      "Computing rank from covariance with rank={'mag': 99}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Creating the source covariance matrix\n",
      "Adjusting source covariance matrix.\n",
      "Computing beamformer filters for 1984 sources\n",
      "Filter computation complete\n",
      "<SourceEstimate | 1984 vertices, subject : sample, tmin : 53.27872350890343 (ms), tmax : 153.1763300880974 (ms), tstep : 6.659840438612929 (ms), data shape : (1984, 16), ~264 kB>\n",
      "Using pyvistaqt 3d backend.\n",
      "\n",
      "Using control points [0.04148847 0.04522559 0.06564754]\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with:\n",
      "pip install qdarkstyle\n",
      "\n",
      "To use light mode, \"qdarkstyle\" has to be installed! You can install it with:\n",
      "pip install qdarkstyle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "hemi: Hemisphere id (ie ‘lh’, ‘rh’, ‘both’, or ‘split’). \n",
    "In the case of ‘lh’, only left hemisphere is shown in the window. \n",
    "In the case of ‘rh’, only right hemispheres is shown in the window. \n",
    "In the case of ‘both’, both hemispheres are shown in the same window. \n",
    "In the case of ‘split’ hemispheres are displayed side-by-side in different viewing panes.\n",
    "\"\"\"\n",
    "\n",
    "hemi='split' # choose from ['lh', 'rh', 'split', 'both']\n",
    "brain3d(s_pred, hemi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df1cf00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-21.12763786 -88.4329071   13.29888344]\n",
      " [-21.47982788 -88.38152313  13.2219944 ]\n",
      " [-21.88400841 -88.28314209  13.2074194 ]\n",
      " ...\n",
      " [-13.28218079  75.84895325  57.0162735 ]\n",
      " [-15.01982021  75.05326843  58.20228577]\n",
      " [-16.47038078  74.3368454   56.61045456]]\n",
      "[[     0      1      3]\n",
      " [     4      3      1]\n",
      " [     0     61     62]\n",
      " ...\n",
      " [153723 153732 153919]\n",
      " [153900 153907 153901]\n",
      " [154073 154322 154245]]\n",
      "[[0.00969072 0.00967974 0.01275246 ... 0.01222476 0.01176346 0.01120899]\n",
      " [0.02300234 0.02311075 0.02096353 ... 0.02240465 0.02239515 0.02228532]\n",
      " [0.00612901 0.00726201 0.00051712 ... 0.002742   0.00300734 0.00319636]\n",
      " ...\n",
      " [0.00467773 0.00444413 0.00331879 ... 0.00406433 0.0043078  0.00445012]\n",
      " [0.00331646 0.00318075 0.00244875 ... 0.00299053 0.00316049 0.00339406]\n",
      " [0.00530668 0.00593612 0.00373083 ... 0.00359215 0.00380004 0.00402161]]\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "from mne import read_surface\n",
    "vertices, faces = mne.read_surface('C:/Users/dimpa/mne_data/MNE-sample-data/subjects/sample/surf/lh.pial')\n",
    "print(vertices)\n",
    "print(faces)\n",
    "print(s_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9660c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertices_list = vertices.tolist()  # Convert vertices to list\n",
    "faces_list = faces.tolist()  # Convert faces to list\n",
    "s_pred_list = s_pred.tolist()  # Convert s_pred matrix to list\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"vertices\": vertices_list,\n",
    "    \"faces\": faces_list,\n",
    "    \"activity\": s_pred_list\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b49688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Serialize data to JSON string\n",
    "json_str = json.dumps(data, indent=4)\n",
    "\n",
    "# To save this JSON string to a file\n",
    "with open('brain_data.json', 'w') as json_file:\n",
    "    json_file.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40357bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from pathlib import Path\n",
    "import scipy.io\n",
    "\n",
    "# Define the paths to the folders\n",
    "data_path = Path(\"C:/Users/dimpa/mne_data/MNE-sample-data/\")\n",
    "subjects_dir = data_path / \"subjects\"\n",
    "\n",
    "# Specify the subject and the surface to use\n",
    "subject = \"sample\"\n",
    "surf = \"inner_skull\"  # Use the inner surface of the skull\n",
    "\n",
    "# Load the brain surface mesh\n",
    "vertices, faces = mne.read_surface(str(subjects_dir / subject / 'bem' / f'{surf}.surf'))\n",
    "\n",
    "# Load detected cells coordinates from .mat file\n",
    "mat_data = scipy.io.loadmat('C:/Users/dimpa/OneDrive - stevens.edu/SSW-555/Existing Solution/ESI_project 2/ESI_project 2/result/sample/Test_result_evoked_LA.mat')\n",
    "detected_cells_coordinates = mat_data['s_pred']\n",
    "\n",
    "# Save the vertices and faces to an .obj file\n",
    "output_obj_path = \"reddetected_cells.obj\"\n",
    "with open(output_obj_path, 'w') as obj_file:\n",
    "    # Write vertices for brain surface\n",
    "    for vertex in vertices:\n",
    "        obj_file.write(f'v {vertex[0]} {vertex[1]} {vertex[2]} 0.5 0.5 0.5\\n')  # Gray color for brain surface\n",
    "    \n",
    "    # Write vertices for detected cells with red color\n",
    "    for cell_coordinates in detected_cells_coordinates:\n",
    "        obj_file.write(f'v {cell_coordinates[0]} {cell_coordinates[1]} {cell_coordinates[2]} 1.0 0.0 0.0\\n')  # Red color for detected cells\n",
    "\n",
    "    # Write faces\n",
    "    for face in faces:\n",
    "        obj_file.write(f'f {\" \".join(str(idx + 1) for idx in face)}\\n')\n",
    "\n",
    "print(f\"Obj file saved: {output_obj_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f073bd84",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
